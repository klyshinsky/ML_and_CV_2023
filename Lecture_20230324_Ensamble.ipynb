{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы ансемблирования в классификации\n",
    "\n",
    "Спасибо за помощь Михаилу Трофимову и [DataGym](https://datagym.ru/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение\n",
    "\n",
    "Анасамбль -- алгоритм, который состоит из нескольких алгоритмов машинного обучения.\n",
    "\n",
    "Общий вид такого алгоритма: $$f(x) = d(h_1(x), h_2(x), \\dots, h_n(x))$$\n",
    "\n",
    "где $h_i(x)$ - i-й используемый базовый алгоритм, $d$ - функция агрегации (решающее правило)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обоснование эффективности\n",
    "\n",
    "Есть несколько способ объяснения эффективности ансамблей, рассмотрим 2 из них.\n",
    "\n",
    "1) **Функциональное обоснование**\n",
    "\n",
    "С помощью ансамбля можно реализовать более сложную разделяющую поверхность, чем с использованием лишь базовых алгоритмов. \n",
    "<center><img src='img/linear_ens.png' style=\"width: 40%\"><center/>\n",
    "    \n",
    "_Можно ли решить задачу с иллюстрации с помощью только линейных моделей? А каким будет решающее правило?_\n",
    "\n",
    "2) **Статистическое обоснование**\n",
    "\n",
    "Будем рассматривать $h_i$ как **независимые** случайные величины с одинаковым матожиданием и одинаковой (конечной) дисперсией.\n",
    "\n",
    "$$ f = \\frac{1}{n}(h_1 + h_2 + \\dots + h_n)$$\n",
    "$$ \\mathbb{E}f =\\frac{1}{n} (\\mathbb{E}h_1 + \\mathbb{E}h_2 + \\dots + \\mathbb{E}h_n) = \\mathbb{E}h $$\n",
    "$$\\mathbb{D}f = \\frac{1}{n^2}(\\mathbb{D}h_1 + \\mathbb{D}h_2 + \\dots + \\mathbb{D}h_n) = \\frac{\\mathbb{D}h}{n}$$\n",
    "    \n",
    "Требование независимости в реальности выполняется редко, \n",
    "ибо базовые классификаторы обучаются на одной и той же выборке, на тот же целевой вектор.\n",
    "\n",
    "**Поэтому при построении ансамблю в него стремятся включать максимально разнообразные модели, \n",
    "чтобы приблизиться к требованию независимости**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод опорных векторов (Support Vector Machine, SVM)\n",
    "\n",
    "Еще одним из методов ансемблирования в смысле п. 1 является [SVM](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%BF%D0%BE%D1%80%D0%BD%D1%8B%D1%85_%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BE%D0%B2). Он строит несколько разделяющих гиперплоскостей, а дальше принимает решение о номере класса в зависимости от сочетаний признаков (больше или меньше каждой из гиперплоскостей). (Математическое изложение в [тексте](http://www.ccas.ru/voron/download/SVM.pdf) и [презентации](http://www.machinelearning.ru/wiki/images/archive/a/a0/20150316112120%21Voron-ML-Lin-SVM.pdf).\n",
    "\n",
    "Формулу, используемую для построения разделяющей поверхности, называют ядром SVM. Для разделения могут использоваться не только гиперплоскости, но и функции более высокого порядка. Наиболее распространенными среди них являются [RBF (Radial Basis Functions)](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B4%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE-%D0%B1%D0%B0%D0%B7%D0%B8%D1%81%D0%BD%D0%B0%D1%8F_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F), фактически переводящие точки в полярные координаты и работающие с углами и расстояниями до центроида.\n",
    "\n",
    "![](img/sphx_glr_plot_iris_svc_0011.png)\n",
    "<a href=\"https://gist.github.com/WittmannF/60680723ed8dd0cb993051a7448f7805\">\n",
    "![](img/6883294a-81c8-11e6-8950-6989e765966a.png)\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Варьирование данных: bagging\n",
    "\n",
    "**Бутстрап (bootstrap)** -- создание выборки путем сэмплирования с повторением\n",
    "\n",
    "<center><img src='img/bootstrap.png' style=\"width: 80%\"><center/>\n",
    "\n",
    "**Бэггинг (bagging)** -- bootstrap + aggregation\n",
    "<center><img src='img/bagging.png' style=\"width: 60%\"><center/>\n",
    "    \n",
    "**Random Subspace Method (RSM)** -- похожая идея, но только не для объектов, а для признаков\n",
    "\n",
    "**Random Patches** -- объединение идеи бустрапа и RSM (то есть сэмплирование и по объектам, и по признакам)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "Boosting, в отличие от bagging'а - это **последовательный** способ построения композиции моделей.\n",
    "\n",
    "Мы постоянно работаем с одним и тем же набором данных, **но** на каждом шаге строим новую базовую модель, которая учитывает ошибки предыдущей модели.\n",
    "\n",
    "Исторически, первым успешным методом бустинга стал **AdaBoost** (ADAptive BOOSTing). В нем каждому объекту присваивается вес, который изменяется в зависимости от того, ошиблась ли на нем очередная композиция базовых алгоритмов или нет. Так же веса имеются и у самих базовых моделей, которые штрафуют их за плохие предсказания. Для задачи классификации этот процесс можно проиллюстрировать следующим образом:\n",
    "<center><img src='img/adaboost.jpg' style=\"width: 80%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг (Gradient Boosting, GBM)\n",
    "<center><img src='img/golf-MSE.png' width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блендинг\n",
    "\n",
    "**Блендинг (блендинг)** -- \"простая\" копозиция алгоритмов. Обычно под этим понимаю обобщенное среднее ответов нескольких алгоритмов.\n",
    "\n",
    "_Примеры: среднее арифметическое, среднее геометрическое, среднее ранков и т.д._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что еще почитать\n",
    "\n",
    "[Вот это](https://neurohive.io/ru/osnovy-data-science/ansamblevye-metody-begging-busting-i-steking/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы голосования\n",
    "\n",
    "Теперь рассмотрим второй путь, когда имеется несколько моделей, проводящих голосование.\n",
    "\n",
    "Попробуем решить несколькими методами следующую задачу. На вход системы поступают тексты, необходимо определять язык текста. Очевидно, задача является задачей многоклассовой классификации. У нас есть несколько путей ее решения.\n",
    "* Построить один многоклассовый классификатор, обучив его на всей обучающей выборке.\n",
    "* Использовать метод классификации, который сам по себе ансамбль, но за счет интерфейса смотрится монолитно.\n",
    "* Обучить несколько многоклассовых классификаторов на разных подвыборках, организовать голосование между ними:\n",
    "    - выбирать класс, за который проголосовало большинство, возвращать его;\n",
    "    - нормировать количество голосов, отданных за каждый из классов, возвращать вероятность ответа.\n",
    "* Обучить $n$ бинарных классификаторов, где $n$ - число классов; надеяться, что проголосует только один классификатор; возвращать $1/m$, где $m$ - количество классификаторов, вернувших ненулевое значение.\n",
    "\n",
    "$$\n",
    "\\textbf{a}  = <a_1, a_2, ..., a_n>, a_i=\\{0,1\\}, \\sum\\limits_{i=1}^n a_i = m \\\\\n",
    "C(\\textbf{a}) = <a_1*1/m, a_2*1/m, ... , a_n*1/m>\n",
    "$$\n",
    "\n",
    "* Обучить $n$ ансамблей из $k$ классификаторов, возвращать класс, за который проголосовало больше всего классификаторов.\n",
    "\n",
    "$$\n",
    "\\textbf{A}  = \\begin{pmatrix}\n",
    "a_{1,1} & a_{1,2} & \\cdots & a_{1,n} \n",
    "\\\\ a_{2,1} & a_{2,2} & \\cdots & a_{2,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \n",
    "\\\\ a_{k,1} & a_{k,2} & \\cdots & a_{k,n} \n",
    "\\end{pmatrix}, \n",
    "a_{i,j}=\\{0,1\\}\n",
    "$$\n",
    "\n",
    "* Всё вышеперечисленное, но каждый классификатор, входящий в состав ансамбля, возвращает вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "                \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"bg\", \"fr\", \"ger\", \"it\", \"rus\", \"rus_orcs\"] #, \"esp\"\n",
    "\n",
    "def prepareFile(filename, size):\n",
    "    with open(filename) as file:\n",
    "        data = file.read()\n",
    "    data = [data[i*size: (i+1)*size] for i in range(int(len(data[:-(len(data) % size)])/size))]\n",
    "    vectorizer = CountVectorizer(analyzer ='char')\n",
    "    transformed = vectorizer.fit_transform(data)\n",
    "    return transformed, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 1000\n",
    "blocks = []\n",
    "vectorizers = []\n",
    "for file in files:\n",
    "    d, v = prepareFile(f\"data/{file}.txt\", block_size)\n",
    "    blocks.append(d)\n",
    "    vectorizers.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((997, 103), 'bg'),\n",
       " ((984, 87), 'fr'),\n",
       " ((999, 105), 'ger'),\n",
       " ((998, 80), 'it'),\n",
       " ((993, 103), 'rus'),\n",
       " ((994, 77), 'rus_orcs')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(b.shape, l) for b, l in zip(blocks, files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bg\n",
      "fr\n",
      "ger\n",
      "it\n",
      "rus\n",
      "rus_orcs\n"
     ]
    }
   ],
   "source": [
    "test_blocks = []\n",
    "test_vectorizers = []\n",
    "for file in files:\n",
    "    print(file)\n",
    "    d, v = prepareFile(f\"data/{file}_test.txt\", block_size)\n",
    "    test_blocks.append(d)\n",
    "    test_vectorizers.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = []\n",
    "for vect in vectorizers:\n",
    "    alphabet.extend(vect.vocabulary_)\n",
    "alphabet = {a:i for i, a in enumerate(list(set(alphabet)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alphabet.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeByAlphabet(block, vectorizer, alphabet):\n",
    "    vect = np.zeros(len(alphabet.keys())+1)\n",
    "    for i in range(block.shape[1]):\n",
    "        index = list(vectorizer.vocabulary_.values()).index(i)\n",
    "        c = list(vectorizer.vocabulary_.keys())[index]\n",
    "        index2 = alphabet.get(c, -1)\n",
    "        vect[index2] = block[0, index]\n",
    "    vect = vect / vect.sum()\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0\n",
      "train - 1\n",
      "train - 2\n",
      "train - 3\n",
      "train - 4\n",
      "train - 5\n",
      "test - 0\n",
      "test - 1\n",
      "test - 2\n",
      "test - 3\n",
      "test - 4\n",
      "test - 5\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "\n",
    "for i, lang in enumerate(blocks):\n",
    "    print(f\"train - {i}\")\n",
    "    for block in lang:\n",
    "        X_train.append(vectorizeByAlphabet(block, vectorizers[i], alphabet))\n",
    "        Y_train.append(i)\n",
    "        \n",
    "for i, lang in enumerate(test_blocks):\n",
    "    print(f\"test - {i}\")\n",
    "    for block in lang:\n",
    "        X_test.append(vectorizeByAlphabet(block, test_vectorizers[i], alphabet))\n",
    "        Y_test.append(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70212766 0.46666667 0.97777778 0.98       0.         1.        ] \n",
      " [1.         0.85714286 0.89795918 1.         0.         0.97916667] \n",
      " [0.825      0.60431655 0.93617021 0.98989899 0.         0.98947368] \n",
      " [ 33  49  49  49  54 144]\n",
      "['bg', 'fr', 'ger', 'it', 'rus', 'rus_orcs']\n",
      "[[ 33   0   0   0   0   0]\n",
      " [  0  42   1   1   5   0]\n",
      " [  0   5  44   0   0   0]\n",
      " [  0   0   0  49   0   0]\n",
      " [ 11  43   0   0   0   0]\n",
      " [  3   0   0   0   0 141]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(X_train, Y_train)\n",
    "Y_hat = rfc.predict(X_test)\n",
    "prec, rec, fscore, support = precision_recall_fscore_support(Y_test, Y_hat)\n",
    "print(prec, \"\\n\", rec, \"\\n\", fscore, \"\\n\", support)\n",
    "print(files)\n",
    "print(confusion_matrix(Y_test, Y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.         0.         0.         0.         0.72727273] \n",
      " [0.96969697 0.         0.         0.         0.         1.        ] \n",
      " [0.98461538 0.         0.         0.         0.         0.84210526] \n",
      " [ 33  49  49  49  54 144]\n",
      "['bg', 'fr', 'ger', 'it', 'rus', 'rus_orcs']\n",
      "[[ 32   0   1   0   0   0]\n",
      " [  0   0   0   0  49   0]\n",
      " [  0  49   0   0   0   0]\n",
      " [  0   0   0   0  49   0]\n",
      " [  0   0   0   0   0  54]\n",
      " [  0   0   0   0   0 144]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edward/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_hat = svc.predict(X_test)\n",
    "prec, rec, fscore, support = precision_recall_fscore_support(Y_test, Y_hat)\n",
    "print(prec, \"\\n\", rec, \"\\n\", fscore, \"\\n\", support)\n",
    "print(files)\n",
    "print(confusion_matrix(Y_test, Y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.         0.         0.         0.         0.72727273] \n",
      " [1. 0. 0. 0. 0. 1.] \n",
      " [1.         0.         0.         0.         0.         0.84210526] \n",
      " [ 33  49  49  49  54 144]\n",
      "['bg', 'fr', 'ger', 'it', 'rus', 'rus_orcs']\n",
      "[[ 33   0   0   0   0   0]\n",
      " [  0   0   0   0  49   0]\n",
      " [  0  49   0   0   0   0]\n",
      " [  0   0  48   0   1   0]\n",
      " [  0   0   0   0   0  54]\n",
      " [  0   0   0   0   0 144]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edward/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', tol=1e-5)\n",
    "\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_hat = svc.predict(X_test)\n",
    "prec, rec, fscore, support = precision_recall_fscore_support(Y_test, Y_hat)\n",
    "print(prec, \"\\n\", rec, \"\\n\", fscore, \"\\n\", support)\n",
    "print(files)\n",
    "print(confusion_matrix(Y_test, Y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
